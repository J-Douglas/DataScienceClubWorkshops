{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Application - Simple Feedforward Neural Network\n",
    "\n",
    "This notebook was inspired from blog: https://victorzhou.com/blog/intro-to-neural-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NumPy library which is used for working with vectors/arrays. It handles operations much faster than traditional Python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neuron Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "  def __init__(self, weights, bias):\n",
    "    self.weights = weights\n",
    "    self.bias = bias\n",
    "\n",
    "  def feedforward(self, inputs):\n",
    "    total = np.dot(self.weights, inputs) + self.bias\n",
    "    return sigmoid(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A single neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our weights are [0,1] and our bias for the neuron is 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([0, 1])\n",
    "bias = 4                   \n",
    "n = Neuron(weights, bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using [2,3] as the inputs from two previous neurons. We apply our understanding of weights, biases, and the activation function (sigmoid) for a neuron to see that the output is...\n",
    "![Calculations](img/perceptron.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9990889488055994\n"
     ]
    }
   ],
   "source": [
    "x = np.array([2, 3])       \n",
    "print(n.feedforward(x))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        weights = np.array([0, 1])\n",
    "        bias = 0\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        return out_o1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our feedforward neural network is ![Neural Network](img/network.png)\n",
    "\n",
    "The calculations for our neural shows that with weights [0,1] and a bias of 0 for each hidden layer neuron and the output neuron yields...\n",
    "![Calculations](img/feedforward.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7216325609518421\n"
     ]
    }
   ],
   "source": [
    "network = FirstNeuralNetwork()\n",
    "x = np.array([2, 3])\n",
    "print(network.feedforward(x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Application - Classification ANN w/ Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the TensorFlow and Keras libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is an open-source machine learning library for Python and Keras is an interface for creating neural networks. There is a video on using TensorFlow with neural networks on the Waterloo Data Science Club Youtube channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fashion-MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the Fashion-MNIST dataset. The Fashion-MNIST dataset is comprised of 60,000 training images and 10,000 testing images. All of the images are labelled. Our goal is to be able to accurately classify images from the dataset. The load_data() function loads the training and testing images and labels into the appropriate NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))\n",
    "print(type(y_train))\n",
    "print(type(x_test))\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['T-shirt', 'Trousers', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x500 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "for i in range(1,10):\n",
    "    fig.add_subplot(3,3,i)\n",
    "    plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(labels[y_train[i]])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In grayscale, pixel intensities vary from 0 (black) to 255 (white), and everything in between are shades of grey. Here is the results from printing the pixel intensities of an image in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   1   0   0   0   0  41 188 103  54  48  43  87 168\n",
      "  133  16   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0  49 136 219 216 228 236 255 255 255 255 217\n",
      "  215 254 231 160  45   0   0   0   0   0]\n",
      " [  0   0   0   0   0  14 176 222 224 212 203 198 196 200 215 204 202 201\n",
      "  201 201 209 218 224 164   0   0   0   0]\n",
      " [  0   0   0   0   0 188 219 200 198 202 198 199 199 201 196 198 198 200\n",
      "  200 200 200 201 200 225  41   0   0   0]\n",
      " [  0   0   0   0  51 219 199 203 203 212 238 248 250 245 249 246 247 252\n",
      "  248 235 207 203 203 222 140   0   0   0]\n",
      " [  0   0   0   0 116 226 206 204 207 204 101  75  47  73  48  50  45  51\n",
      "   63 113 222 202 206 220 224   0   0   0]\n",
      " [  0   0   0   0 200 222 209 203 215 200   0  70  98   0 103  59  68  71\n",
      "   49   0 219 206 214 210 250  38   0   0]\n",
      " [  0   0   0   0 247 218 212 210 215 214   0 254 243 139 255 174 251 255\n",
      "  205   0 215 217 214 208 220  95   0   0]\n",
      " [  0   0   0  45 226 214 214 215 224 205   0  42  35  60  16  17  12  13\n",
      "   70   0 189 216 212 206 212 156   0   0]\n",
      " [  0   0   0 164 235 214 211 220 216 201  52  71  89  94  83  78  70  76\n",
      "   92  87 206 207 222 213 219 208   0   0]\n",
      " [  0   0   0 106 187 223 237 248 211 198 252 250 248 245 248 252 253 250\n",
      "  252 239 201 212 225 215 193 113   0   0]\n",
      " [  0   0   0   0   0  17  54 159 222 193 208 192 197 200 200 200 200 201\n",
      "  203 195 210 165   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  47 225 192 214 203 206 204 204 205 206 204\n",
      "  212 197 218 107   0   0   0   0   0   0]\n",
      " [  0   0   0   0   1   6   0  46 212 195 212 202 206 205 204 205 206 204\n",
      "  212 200 218  91   0   3   1   0   0   0]\n",
      " [  0   0   0   0   0   1   0  11 197 199 205 202 205 206 204 205 207 204\n",
      "  205 205 218  77   0   5   0   0   0   0]\n",
      " [  0   0   0   0   0   3   0   2 191 198 201 205 206 205 205 206 209 206\n",
      "  199 209 219  74   0   5   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0 188 197 200 207 207 204 207 207 210 208\n",
      "  198 207 221  72   0   4   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0 215 198 203 206 208 205 207 207 210 208\n",
      "  200 202 222  75   0   4   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 212 198 209 206 209 206 208 207 211 206\n",
      "  205 198 221  80   0   3   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 204 201 205 208 207 205 211 205 210 210\n",
      "  209 195 221  96   0   3   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 202 201 205 209 207 205 213 206 210 209\n",
      "  210 194 217 105   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 204 204 205 208 207 205 215 207 210 208\n",
      "  211 193 213 115   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 204 207 207 208 206 206 215 210 210 207\n",
      "  212 195 210 118   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 198 208 208 208 204 207 212 212 210 207\n",
      "  211 196 207 121   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 198 210 207 208 206 209 213 212 211 207\n",
      "  210 197 207 124   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 172 210 203 201 199 204 207 205 204 201\n",
      "  205 197 206 127   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 188 221 214 234 236 238 244 244 244 240\n",
      "  243 214 224 162   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 139 146 130 135 135 137 125 124 125 121\n",
      "  119 114 130  76   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change the type of the pixel intensities in the images from integer to float so that we can normalize. We normalize pixel intensities to make calculating the gradient easier and so that the convergence speed is improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are reshaping the data so that the images are flattened from 2-dimension to 1-dimensions. The original images in the Fashion-MNIST dataset are 28 by 28 pixels so a 1-dimensional array will have 784 elements corresponding to every pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://www.researchgate.net/profile/Jose_Padarian/publication/334507958/figure/fig1/AS:781537293377537@1563344419499/Example-of-two-encodings-of-the-phrase-red-sticky-clay-numerical-encoding-and-one-hot.ppm)\n",
    "At the moment, the labels for all the images range from 0 to 9 and they refer to the element in the labels list. We one-hot encode them to create vectors which correspond to the output layer of the neural network when the model predicts a particular label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                23550     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 639,300\n",
      "Trainable params: 639,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(784, activation='sigmoid', input_dim=784))\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the model means we are how we will train the model. We are using the categorical crossentropy loss function. We are using the stochastic gradient descent for our optimizer. The metric that we will be using is accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 2.0232 - accuracy: 0.4704\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 1.4606 - accuracy: 0.6176\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 1.1653 - accuracy: 0.6493\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.9956 - accuracy: 0.6851\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.8847 - accuracy: 0.7103\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.8089 - accuracy: 0.7278\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.7551 - accuracy: 0.7374\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.7152 - accuracy: 0.7441\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.6842 - accuracy: 0.7532\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.6589 - accuracy: 0.7608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fddd5825950>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=50, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 28us/step\n",
      "Test accuracy: 0.7596\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(print('Test accuracy:', round(test_acc,4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
